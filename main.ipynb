{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/diffusers.git accelerate>=0.16.0 torchvision transformers>=4.25.1 ftfy tensorboard Jinja2 datasets wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/katryo/jupyter-train-controlnet-sdxl.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "root_dir          = \"/content\"\n",
    "drive_dir         = os.path.join(root_dir, \"drive/MyDrive\")\n",
    "train_controlnet_dir = os.path.join(drive_dir, \"train-controlnet\")\n",
    "validation_dir   = os.path.join(train_controlnet_dir, \"validation\")\n",
    "\n",
    "def mount_drive(dir):\n",
    "    if not os.path.exists(drive_dir):\n",
    "        drive.mount(os.path.dirname(drive_dir))\n",
    "    output_dir  = os.path.join(train_controlnet_dir, \"output\")\n",
    "\n",
    "    return output_dir\n",
    "\n",
    "\n",
    "output_dir      = mount_drive(drive_dir)\n",
    "\n",
    "for dir in [train_controlnet_dir, output_dir, validation_dir]:\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "validation_image_path_a = os.path.join(validation_dir, \"validation-depth-a.png\")\n",
    "validation_image_path_b = os.path.join(validation_dir, \"validation-depth-b.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch ./jupyter-train-controlnet-sdxl/train_controlnet_sdxl.py \\\n",
    " --pretrained_model_name_or_path=\"katryo/mkcface-2-diffusers\" \\\n",
    "# stabilityai/stable-diffusion-xl-base-1.0 \\\n",
    " --controlnet_model_name_or_path=\"diffusers/controlnet-depth-sdxl-1.0\" \\\n",
    " --hub_model_id=\"controlnet-mkcface-depth-2\" \\\n",
    " --output_dir=$output_dir \\\n",
    " --dataset_name=katryo/mkcface-depth-1 \\\n",
    " --mixed_precision=\"fp16\" \\\n",
    " --resolution=1024 \\\n",
    "#  --resume_from_checkpoint=\"checkpoint-12000\" \\\n",
    " --image_column=\"image\" \\\n",
    " --conditioning_image_column=\"condition_image\" \\\n",
    " --caption_column=\"image_caption\" \\\n",
    " --learning_rate=1e-5 \\\n",
    " --max_train_steps=12000 \\\n",
    " --checkpointing_steps=4000 \\\n",
    " --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\"\\\n",
    " --tracker_project_name \"controlnet-mkcface-depth-2\" \\\n",
    " --validation_image $validation_image_path_a $validation_image_path_b \\\n",
    " --validation_prompt \"angry, 1girl, solo, long hair, looking at viewer, bangs, brown hair, brown eyes, lips, portrait, close-up\" \"frown, 1girl, solo, looking at viewer, bangs, blue eyes, blonde hair, lips, portrait, close-up\" \\\n",
    " --validation_steps=2000 \\\n",
    " --train_batch_size=1 \\\n",
    " --gradient_accumulation_steps=4 \\\n",
    " --report_to=\"wandb\" \\\n",
    " --seed=42 \\\n",
    " --push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch ./jupyter-train-controlnet-sdxl/train_controlnet_sdxl.py \\\n",
    " --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
    " --hub_model_id=\"controlnet-facesynthetics-spiga-sdxl-10000\" \\\n",
    " --output_dir=$output_dir \\\n",
    " --dataset_name=multimodalart/facesyntheticsspigacaptioned \\\n",
    " --mixed_precision=\"fp16\" \\\n",
    " --resolution=512 \\\n",
    " --image_column=\"image\" \\\n",
    " --conditioning_image_column=\"spiga_seg\" \\\n",
    " --caption_column=\"image_caption\" \\\n",
    " --learning_rate=1e-5 \\\n",
    " --resume_from_checkpoint=checkpoint-10000 \\\n",
    " --max_train_steps=10000 \\\n",
    " --checkpointing_steps=5000 \\\n",
    " --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\"\\\n",
    " --tracker_project_name \"controlnet-spiga-sdxl\" \\\n",
    " --validation_image $validation_image_path_a $validation_image_path_b \\\n",
    " --validation_prompt \"a close-up of a man\" \"a close-up of a woman\" \\\n",
    " --validation_steps=5000 \\\n",
    " --train_batch_size=4 \\\n",
    " --gradient_accumulation_steps=4 \\\n",
    " --report_to=\"wandb\" \\\n",
    " --seed=42 \\\n",
    " --push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
